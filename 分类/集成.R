# 集成

# 增强预测性能

# 通过构造一系列分类器，通常时小型决策树，然后为预测进行加权投票，以便对新的数据点分类

# 从本质上来讲，集成是一种监督学习工具， 将很多弱分类器组合在一起，力图生成一个强分类器
# 两种基本方法

# 1. 套袋法(bagging)
# 集成的每个模型投票权重都相同
# 例子 ，随机森林算法

# 2. 提升法 (boosting)
# 着重训练之前模型中误分类的训练实例
# 上一个模型计算出错误分类，下一个模型中重新分配权重

# 3. 交叉融合法
# 当复合模型更少更复杂时，比提升法和套袋法更合适

# 熟悉集成最好的方法，是用 randomForest 算法来实验分类和回归



